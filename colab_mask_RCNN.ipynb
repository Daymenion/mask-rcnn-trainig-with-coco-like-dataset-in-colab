{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_mask_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daymenion/mask-rcnn-trainnig-with-coco-like-dataset/blob/main/colab_mask_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_xR6G1hCCEy"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAW_rlt1Kvx2"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS0L9NyLpdbZ"
      },
      "source": [
        "# ***You should give your train, test and valid data from the drive, if you want you do not run them and set the paths as you wish, but I recommend this for model health.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vNeDBfmIryp"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ln -s /content/drive/My\\ Drive/ /mydrive\n",
        "!cp /content/Mask_RCNN/requirements.txt /content/\n",
        "!cp -av /content/Mask_RCNN/mrcnn/ /content/\n",
        "\n",
        "\n",
        "\n",
        "!cp -av /mydrive/MaskRcnn/train/ /content/\n",
        "!cp -av /mydrive/MaskRcnn/test/ /content/\n",
        "!cp -av /mydrive/MaskRcnn/valid/ /content/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPKnZTDHXpLO"
      },
      "source": [
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip uninstall keras -y\n",
        "!pip uninstall keras-nightly -y\n",
        "!pip uninstall keras-Preprocessing -y\n",
        "!pip uninstall keras-vis -y\n",
        "!pip uninstall tensorflow -y\n",
        "!pip uninstall h5py -y\n",
        "\n",
        "!pip install tensorflow==1.13.1\n",
        "!pip install keras==2.0.8\n",
        "!pip install h5py==2.10.0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qtdb9fq0XvTV"
      },
      "source": [
        "import os\n",
        "# Go inside MaskRCNN and start install\n",
        "os.chdir('/content/Mask_RCNN')\n",
        "!python3 setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Gd70jQMqwP"
      },
      "source": [
        "# One step back and start\n",
        "os.chdir('../')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb-oh5eGL4My"
      },
      "source": [
        "import warnings\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "import cv2\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.image as mpimg\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn.visualize import display_images\n",
        "from mrcnn.visualize import display_instances\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn.model import log\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "import shutil\n",
        "import urllib\n",
        "\n",
        "import skimage.io\n",
        "# Root directory of the project\n",
        "from Mask_RCNN.mrcnn import utils, config\n",
        "from mrcnn.config import Config\n",
        "from Mask_RCNN.mrcnn.visualize import random_colors\n",
        "\n",
        "!cp -av /content/Mask_RCNN/samples/coco/ /content/\n",
        "# Root directory of the project\n",
        "ROOT_DIR = \"./\"\n",
        "MODEL_SAVE_DIR = \"/content/drive/MyDrive/MaskRcnn/model\"\n",
        "\n",
        "DEFAULT_LOGS_DIR = os.path.join(MODEL_SAVE_DIR)\n",
        "\n",
        "MODEL_DIR = os.path.join(MODEL_SAVE_DIR)\n",
        "\n",
        "# Import COCO config\n",
        "sys.path.append(os.path.join(\"/content/Mask_RCNN/samples/coco\"))  # To find local version\n",
        "import coco\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "from PIL import Image, ImageDraw\n",
        "import tkinter\n",
        "import matplotlib\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2lypmWlKt9G"
      },
      "source": [
        "\n",
        "# COCO Class names\n",
        "class_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n",
        "\n",
        "COCO_MODEL_URL = \"https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5\"\n",
        "\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(MODEL_SAVE_DIR)\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(\"mask_rcnn_coco.h5\")\n",
        "\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9qGBaRKHt2u"
      },
      "source": [
        "class CustomConfig(coco.CocoConfig):\n",
        "    \"\"\"Configuration for training on the your dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the your dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        self.NUM_CLASSES = num_classes\n",
        "        super().__init__()\n",
        "\n",
        "    NAME = \"trained_\"\n",
        "\n",
        "    # Train on 1 GPU and 1 image per GPU. Batch size is 1 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "\n",
        "    # All of our training images are 512x512\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "\n",
        "    # You can experiment with this number to see if it improves training\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # This is how often validation is run. If you are using too much hard drive space\n",
        "    # on saved models (in the MODEL_DIR), try making this value larger.\n",
        "    VALIDATION_STEPS = 5\n",
        "\n",
        "    # Matterport originally used resnet101, but I downsized to fit it on my graphics card\n",
        "    BACKBONE = 'resnet101'\n",
        "\n",
        "    DETECTION_MIN_CONFIDENCE = 0.6\n",
        "\n",
        "    # To be honest, I haven't taken the time to figure out what these do\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "    MAX_GT_INSTANCES = 50\n",
        "    POST_NMS_ROIS_INFERENCE = 500\n",
        "    POST_NMS_ROIS_TRAINING = 1000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSt65ywUHwjq"
      },
      "source": [
        "\n",
        "class InferenceConfig(CustomConfig):\n",
        "    def __init__(self, num_classes = 2):\n",
        "        super().__init__(num_classes = num_classes)\n",
        "\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    DETECTION_MIN_CONFIDENCE = 0.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBQVPZXGMww_"
      },
      "source": [
        "class CocoLikeDataset(utils.Dataset):\n",
        "\n",
        "    def load_data(self, annotation_json, images_dir):\n",
        "        \"\"\" Load the your dataset\n",
        "            annotation_json: The path to the coco annotations json file\n",
        "            images_dir: The directory holding the images referred to by the json file\n",
        "        \"\"\"\n",
        "        # Load json from file\n",
        "        json_file = open(annotation_json)\n",
        "        coco_json = json.load(json_file)\n",
        "        json_file.close()\n",
        "\n",
        "        # Add the class names using the base method from utils.Dataset\n",
        "        source_name = \"coco_like\"\n",
        "        for category in coco_json['categories']:\n",
        "            class_id = category['id']\n",
        "            class_name = category['name']\n",
        "            if class_id < 1:\n",
        "                print('Error: Class id for \"{}\" cannot be less than one. (0 is reserved for the background)'.format(\n",
        "                    class_name))\n",
        "                return\n",
        "\n",
        "            self.add_class(source_name, class_id, class_name)\n",
        "\n",
        "        # Get all annotations\n",
        "        annotations = {}\n",
        "        for annotation in coco_json['annotations']:\n",
        "            image_id = annotation['image_id']\n",
        "            if image_id not in annotations:\n",
        "                annotations[image_id] = []\n",
        "            annotations[image_id].append(annotation)\n",
        "\n",
        "        # Get all images and add them to the dataset\n",
        "        seen_images = {}\n",
        "        for image in coco_json['images']:\n",
        "            image_id = image['id']\n",
        "            if image_id in seen_images:\n",
        "                print(\"Warning: Skipping duplicate image id: {}\".format(image))\n",
        "            else:\n",
        "                seen_images[image_id] = image\n",
        "                try:\n",
        "                    image_file_name = image['file_name']\n",
        "                    image_width = image['width']\n",
        "                    image_height = image['height']\n",
        "                except KeyError as key:\n",
        "                    print(\"Warning: Skipping image (id: {}) with missing key: {}\".format(image_id, key))\n",
        "\n",
        "                image_path = os.path.abspath(os.path.join(images_dir, image_file_name))\n",
        "                image_annotations = annotations[image_id]\n",
        "\n",
        "                # Add the image using the base method from utils.Dataset\n",
        "                self.add_image(\n",
        "                    source=source_name,\n",
        "                    image_id=image_id,\n",
        "                    path=image_path,\n",
        "                    width=image_width,\n",
        "                    height=image_height,\n",
        "                    annotations=image_annotations\n",
        "                )\n",
        "\n",
        "        # Adding the rest COCO classed\n",
        "        # for i in range(0,len(class_names)):\n",
        "        #     self.add_class(class_names[i], i + len(self.class_info), class_names[i])\n",
        "        #     #i + len(self.class_info) means after adding my class and BackGround Class\n",
        "        #\n",
        "        # print(\"Total Classes: \",len(self.class_info))\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\" Load instance masks for the given image.\n",
        "        MaskRCNN expects masks in the form of a bitmap [height, width, instances].\n",
        "        Args:\n",
        "            image_id: The id of the image to load masks for\n",
        "        Returns:\n",
        "            masks: A bool array of shape [height, width, instance count] with\n",
        "                one mask per instance.\n",
        "            class_ids: a 1D array of class IDs of the instance masks.\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        annotations = image_info['annotations']\n",
        "        instance_masks = []\n",
        "        class_ids = []\n",
        "\n",
        "        for annotation in annotations:\n",
        "            class_id = annotation['category_id']\n",
        "            mask = Image.new('1', (image_info['width'], image_info['height']))\n",
        "            mask_draw = ImageDraw.ImageDraw(mask, '1')\n",
        "            for segmentation in annotation['segmentation']:\n",
        "                mask_draw.polygon(segmentation, fill=1)\n",
        "                bool_array = np.array(mask) > 0\n",
        "                instance_masks.append(bool_array)\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "        mask = np.dstack(instance_masks)\n",
        "        class_ids = np.array(class_ids, dtype=np.int32)\n",
        "\n",
        "        return mask, class_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE4g4bXWMMCj"
      },
      "source": [
        "def download_trained_weights(coco_model_path, verbose=1):\n",
        "    if verbose > 0:\n",
        "        print(\"Downloading pretrained model to \" + coco_model_path + \" ...\")\n",
        "    with urllib.request.urlopen(COCO_MODEL_URL) as resp, open(coco_model_path, 'wb') as out:\n",
        "        shutil.copyfileobj(resp, out)\n",
        "    if verbose > 0:\n",
        "        print(\"... done downloading pretrained model!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOsjkt2SMXNm"
      },
      "source": [
        "def load_data():\n",
        "\n",
        "    dataset_train = CocoLikeDataset()\n",
        "    dataset_train.load_data('/content/train/coco_annotations.json', '/content/train/images')\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    dataset_val = CocoLikeDataset()\n",
        "    dataset_val.load_data('/content/valid/coco_annotations.json', '/content/valid/images')\n",
        "    dataset_val.prepare()\n",
        "\n",
        "    return dataset_train,dataset_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLk5k1aYMaNI"
      },
      "source": [
        "\n",
        "def show_data():\n",
        "    dataset_train,dataset_val = load_data()\n",
        "    image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "    for image_id in image_ids:\n",
        "        image = dataset_train.load_image(image_id)\n",
        "        mask, class_ids = dataset_train.load_mask(image_id)\n",
        "        visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRind74UMb92"
      },
      "source": [
        "def create_config_load_model():\n",
        "    config = CustomConfig(num_classes=2)\n",
        "    config.display()\n",
        "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                              model_dir=MODEL_DIR)\n",
        "\n",
        "    # Which weights to start with?\n",
        "    init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "    if init_with == \"imagenet\":\n",
        "        model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "    elif init_with == \"coco\":\n",
        "        # Load weights trained on MS COCO, but skip layers that\n",
        "        # are different due to the different number of classes\n",
        "        model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                           exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "                                    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "    elif init_with == \"last\":\n",
        "        # Load the last model you trained and continue training\n",
        "        model.load_weights(model.find_last(), by_name=True)\n",
        "\n",
        "    return model,config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF6qi1veMeLI"
      },
      "source": [
        "def train_model():\n",
        "    model,config = create_config_load_model()\n",
        "    dataset_train, dataset_val = load_data()\n",
        "\n",
        "    start_train = time.time()\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=5,\n",
        "                layers='heads')\n",
        "    end_train = time.time()\n",
        "    minutes = round((end_train - start_train) / 60, 2)\n",
        "    print(f'Training took {minutes} minutes')\n",
        "\n",
        "    print(\"Saving model\")\n",
        "    model.keras_model.save_weights('mask_rcnn.h5')\n",
        "\n",
        "    return dataset_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvFG5wPeMiq0"
      },
      "source": [
        "def load_pretrained_model():\n",
        "    # Directory to save logs and trained model\n",
        "    MODEL_DIR = os.path.join(\"logs\")\n",
        "    # Local path to trained weights file\n",
        "    COCO_MODEL_PATH = os.path.join(\"mask_rcnn.h5\")\n",
        "\n",
        "\n",
        "    config = InferenceConfig(num_classes = 2)\n",
        "    config.display()\n",
        "    # Create model object in inference mode.\n",
        "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=config)\n",
        "    # Load weights trained on MS-COCO\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJGi-LtFMlhq"
      },
      "source": [
        "def predict_static_image(image_name):\n",
        "    model = load_pretrained_model()\n",
        "    dataset_train,dataset_valid  = load_data()\n",
        "\n",
        "    file_name = image_name\n",
        "    image = skimage.io.imread(file_name)\n",
        "    # Run detection\n",
        "    results = model.detect([image], verbose=1)\n",
        "\n",
        "    # Visualize results\n",
        "    r = results[0]\n",
        "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'],\n",
        "                                dataset_train.class_names, r['scores'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeCCXVihOENY"
      },
      "source": [
        "# show_data()\n",
        "\n",
        "dataset_train = train_model()\n",
        "print(\"Dataset Class Names\")\n",
        "print(dataset_train.class_names)\n",
        "\n",
        "predict_static_image(\"/content/test/test4.jpg\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyXH7ik0s0-1"
      },
      "source": [
        "#for video source\n",
        "!mkdir videos\n",
        "!wget \"the video which came from api or local video\" -P ./videos\n",
        "!ls ./videos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAxntPl5zehr"
      },
      "source": [
        "#this is for coco weights if you want to try for your model, u have to change path and names\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def random_colors(N):\n",
        "    np.random.seed(1)\n",
        "    colors = [tuple(255 * np.random.rand(3)) for _ in range(N)]\n",
        "    return colors\n",
        "\n",
        "\n",
        "def apply_mask(image, mask, color, alpha=0.5):\n",
        "    \"\"\"apply mask to image\"\"\"\n",
        "    for n, c in enumerate(color):\n",
        "        image[:, :, n] = np.where(\n",
        "            mask == 1,\n",
        "            image[:, :, n] * (1 - alpha) + alpha * c,\n",
        "            image[:, :, n]\n",
        "        )\n",
        "    return image\n",
        "\n",
        "\n",
        "def display_instances(image, boxes, masks, ids, names, scores):\n",
        "    \"\"\"\n",
        "        take the image and results and apply the mask, box, and Label\n",
        "    \"\"\"\n",
        "    n_instances = boxes.shape[0]\n",
        "    colors = random_colors(n_instances)\n",
        "\n",
        "    if not n_instances:\n",
        "        print('NO INSTANCES TO DISPLAY')\n",
        "    else:\n",
        "        assert boxes.shape[0] == masks.shape[-1] == ids.shape[0]\n",
        "\n",
        "    for i, color in enumerate(colors):\n",
        "        if not np.any(boxes[i]):\n",
        "            continue\n",
        "\n",
        "        y1, x1, y2, x2 = boxes[i]\n",
        "        label = names[ids[i]]\n",
        "        score = scores[i] if scores is not None else None\n",
        "        caption = '{} {:.2f}'.format(label, score) if score else label\n",
        "        mask = masks[:, :, i]\n",
        "\n",
        "        image = apply_mask(image, mask, color)\n",
        "        image = cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "        image = cv2.putText(\n",
        "            image, caption, (x1, y1), cv2.FONT_HERSHEY_COMPLEX, 0.7, color, 2\n",
        "        )\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "        test everything\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import sys\n",
        "    import coco\n",
        "    import utils\n",
        "    import model as modellib\n",
        "    \n",
        "    # We use a K80 GPU with 24GB memory, which can fit 3 images.\n",
        "    batch_size = 3\n",
        "\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "    VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n",
        "    VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")\n",
        "    COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "    if not os.path.exists(COCO_MODEL_PATH):\n",
        "        utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "    class InferenceConfig(coco.CocoConfig):\n",
        "        GPU_COUNT = 1\n",
        "        IMAGES_PER_GPU = batch_size\n",
        "\n",
        "    config = InferenceConfig()\n",
        "    config.display()\n",
        "\n",
        "    model = modellib.MaskRCNN(\n",
        "        mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
        "    )\n",
        "\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "    class_names = [\n",
        "        'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "        'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "        'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "        'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "        'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "        'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "        'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "        'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "        'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "        'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "        'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "        'teddy bear', 'hair drier', 'toothbrush'\n",
        "    ]\n",
        "\n",
        "    capture = cv2.VideoCapture(os.path.join(VIDEO_DIR, 'trailer1.mp4'))\n",
        "    try:\n",
        "        if not os.path.exists(VIDEO_SAVE_DIR):\n",
        "            os.makedirs(VIDEO_SAVE_DIR)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory of data')\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    # these 2 lines can be removed if you dont have a 1080p camera.\n",
        "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
        "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = capture.read()\n",
        "        # Bail out when the video file ends\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        # Save each frame of the video to a list\n",
        "        frame_count += 1\n",
        "        frames.append(frame)\n",
        "        print('frame_count :{0}'.format(frame_count))\n",
        "        if len(frames) == batch_size:\n",
        "            results = model.detect(frames, verbose=0)\n",
        "            print('Predicted')\n",
        "            for i, item in enumerate(zip(frames, results)):\n",
        "                frame = item[0]\n",
        "                r = item[1]\n",
        "                frame = display_instances(\n",
        "                    frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
        "                )\n",
        "                name = '{0}.jpg'.format(frame_count + i - batch_size)\n",
        "                name = os.path.join(VIDEO_SAVE_DIR, name)\n",
        "                cv2.imwrite(name, frame)\n",
        "                print('writing to file:{0}'.format(name))\n",
        "            # Clear the frames array to start the next batch\n",
        "            frames = []\n",
        "\n",
        "    capture.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2svP3NGiznTL"
      },
      "source": [
        "!ls ./videos/save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5kBHkH3zs3W"
      },
      "source": [
        "video = cv2.VideoCapture(os.path.join(VIDEO_DIR, 'trailer1.mp4'));\n",
        "\n",
        "# Find OpenCV version\n",
        "(major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "if int(major_ver)  < 3 :\n",
        "    fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "    print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "else :\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "\n",
        "video.release();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWQzdEqDzvst"
      },
      "source": [
        "def make_video(outvid, images=None, fps=30, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        " \n",
        "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
        "    By default, the video will have the size of the first image.\n",
        "    It will resize every image to this size before adding them to the video.\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        if not os.path.exists(image):\n",
        "            raise FileNotFoundError(image)\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Directory of images to run detection on\n",
        "ROOT_DIR = os.getcwd()\n",
        "VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n",
        "VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")\n",
        "images = list(glob.iglob(os.path.join(VIDEO_SAVE_DIR, '*.*')))\n",
        "# Sort the images by integer index\n",
        "images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n",
        "\n",
        "outvid = os.path.join(VIDEO_DIR, \"out.mp4\")\n",
        "make_video(outvid, images, fps=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t72w-fulz0ht"
      },
      "source": [
        "!ls -alh ./videos/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPi8v3lez_nr"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('videos/out.mp4')\n",
        "#videonun indirilmesi, drive a yuklenmesi ya da kullaniciya gonderilmesi bu adimda yapilir"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}